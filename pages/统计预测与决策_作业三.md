- ![56fccaa6ea9e7872259078bf7204397.jpg](../assets/56fccaa6ea9e7872259078bf7204397_1695428883616_0.jpg)
	- (1) : $n=10$，经计算得：
	  $\sum x=1700$    $\sum x^{2}=322000$     $\sum xy=205500$    $\sum y =1110$     $\sum y^{2} =132100$
	  $$\hat{b_{1}}={{\sum(x- \overline{x})(y- \overline{y})} \over{\sum(x- \overline{x})^{2}} }= {{n \sum{xy}-\sum{x} \sum{y}} \over{n \sum{x^{2}}-( \sum x)^{2}}}={{10 \times 205500-1700 \times 1110} \over {10 \times 322000 -1700^{2}}} \approx 0.5091$$
	  $$\hat{b_{0}}= {\overline{y} - \hat{b_{1}} \overline{x}}={{{1110} \over{10}} -0.5091 \times{{1700} \over{10}}} \approx 24.453$$
	  因此，建立的一元线性回归方程为：
	  $$\hat{y} = 24.453+0.5091 \times x$$
	- (2): 计算可决系数
	  $$R^{2}= {{{\overline{b}_{1}^{2}} \sum{\left( x - \overline{x} \right)}^{2}} \over{\sum{\left( y - \overline{y} \right)}^{2}}}={{\overline{b}_{1}^{2}(\sum{x^{2}-n \overline{x}^{2}})} \over {\sum{y^{2}-n \hat{y}^{2}}}}={{0.5091^{2} \times (322000-10 \times 170^{2})} \over {132100-10 \times 111^{2}}} 
	  \approx {0.9621}$$
	- (3): 模型的显著性检验统计量
	  $$F={{R^{2}(n-2)} \over {1-R^{2}}}={{0.9621 \times 8} \over {1-0.9621}} \approx 253.8522$$
	  $$t \approx 14.25>t_{0.025}(8)$$
	  所以拒绝原假设，认为所建立的线性回归模型是显著的。
	  ---
- ![c0766d128e9f3a9ecc34b61727ffef3.jpg](../assets/c0766d128e9f3a9ecc34b61727ffef3_1695437098033_0.jpg)
	- (1) :$n=10$，经计算得：
	  $\sum x=56400$    $\sum x^{2}=32604000$     $\sum xy=818145.0$  $\sum y =143.55$   $\sum y^{2} =2073.3775$
	  $$r={{\sum(x- \overline{x})(x- \overline{x})} \over \sqrt{\sum(x- \overline{x})^{2} \sum(y- \overline{y})^{2}}} \approx 0.848$$
	- (2):
	  $$\hat{b_{1}}={{\sum(x- \overline{x})(y- \overline{y})} \over{\sum(x- \overline{x})^{2}} } \approx 0.00107$$
	  $$\hat{b_{0}}= {\overline{y} - \hat{b_{1}} \overline{x}} \approx 8.304$$
	  因此，建立的一元线性回归方程为：
	  $$\hat{y} = 8.304+ 0.00107 \times x$$
	- (3): 
	  $$R^{2}= {{{\overline{b}_{1}^{2}} \sum{\left( x - \overline{x} \right)}^{2}} \over{\sum{\left( y - \overline{y} \right)}^{2}}} \approx 0.719$$
	- (4): D-W值为1.5620239997734038
	  ---
- ![4e8f327a23221033fa07dc1f3a19723.jpg](../assets/4e8f327a23221033fa07dc1f3a19723_1695428897025_0.jpg){:height 201, :width 675}
	- (1) : $n=10$，经计算得：
	  $\sum x=777$    $\sum x^{2}=70903$     $\sum xy=132938$    $\sum y =1657$   $\sum y^{2} =277119$
	  $$r={{\sum(x- \overline{x})(x- \overline{x})} \over \sqrt{\sum(x- \overline{x})^{2} \sum(y- \overline{y})^{2}}} \approx 0.8078$$
	  $$R^{2} \approx 0.6525$$
	- (2):
	  $$\hat{b_{1}}={{\sum(x- \overline{x})(y- \overline{y})} \over{\sum(x- \overline{x})^{2}} } \approx  0.3978$$
	  $$\hat{b_{0}}= {\overline{y} - \hat{b_{1}} \overline{x}} \approx 134.7892$$
	  因此，建立的一元线性回归方程为：
	  $$\hat{y} = 134.7892+ 0.3978 \times x$$
	  模型的显著性检验统计量
	  $$F={{R^{2}(n-2)} \over {1-R^{2}}}={{0.6525 \times 8} \over {1-0.6525}} \approx 15.0206$$
	  $$t \approx 3.8756>t_{0.025}(8)$$
	  拒绝原假设，在 $\alpha=0.05$下认为所建立的线性回归模型是显著的。
	  ---
- 一元线性模型相关参数求解程序
  ````python
  import numpy as np
  import statsmodels.api as sm
  from sklearn.linear_model import LinearRegression
  from sklearn.metrics import r2_score
  
  
  def calculate_r2(x, y):
      # 将x和y转换为numpy数组并进行reshape
      x = np.array(x).reshape(-1, 1)
      y = np.array(y).reshape(-1, 1)
  
      # 创建线性回归模型
      model = LinearRegression()
  
      # 拟合模型
      model.fit(x, y)
  
      # 预测y值
      y_pred = model.predict(x)
  
      # 计算R^2值
      r2 = r2_score(y, y_pred)
      return r2
      
  def calculate_dw(x, y):
      # 将x和y转换为numpy数组
      x = np.array(x)
      y = np.array(y)
  
      # 添加常数列
      X = sm.add_constant(x)
  
      # 创建OLS模型
      model = sm.OLS(y, X)
  
      # 拟合模型
      results = model.fit()
  
      # 提取残差
      residuals = results.resid
  
      # 计算D-W值
      dw = np.sum(np.diff(residuals) ** 2) / np.sum(residuals ** 2)
  
      return dw
      
  # 两个数组分别代表x和y的值
  # x = [4100,5400,6300,5400,4800,4600,6200,6100,6400,7100]
  # y = [12.50,13.80,14.25,14.25,14.50,13.00,14.00,15.00,15.75,16.50]
  x=[40,42,48,55,65,79,88,100,120,140]
  y=[150,140,160,170,150,162,185,165,190,185]
  
  X=0
  XX=0
  Y=0
  YY=0
  XY=0
  for i in range(10):
     X+=x[i]
     XX+=x[i]*x[i]
     Y+=y[i]
     YY+=y[i]**2
     XY+=x[i]*y[i]
  
  def linear_regression(x, y):
      n = len(x)
      x_mean = np.mean(x)
      y_mean = np.mean(y)
  
      # 计算回归系数
      numerator = np.sum((x - x_mean) * (y - y_mean))
      denominator = np.sum((x - x_mean) ** 2)
      slope = numerator / denominator
      intercept = y_mean - slope * x_mean
  
      return slope, intercept
  
  # 使用numpy的corrcoef函数计算相关系数
  r = np.corrcoef(x, y)[0, 1]
  
  r2 = calculate_r2(x, y)
  print("R^2值:", r2)
  
  r = np.corrcoef(x, y)[0, 1]
  
  print("相关系数r为:", r)
  
  x = np.array(x)
  y = np.array(y)
  print("X:",X)
  print("Y:",Y)
  print("XX:",XX)
  print("YY:",YY)
  print("XY:",XY)
  
  # 计算回归系数
  slope, intercept = linear_regression(x, y)
  
  print("回归系数（斜率）：", slope)
  print("回归系数（截距）：", intercept)
  
  # 计算D-W值
  dw = calculate_dw(x, y)
  print("D-W值:", dw)
  
  f=r2*(len(x)-2)/(1-r2)
  print("F:",f)
  t=f**0.5
  print("t:",t)
  ```